# Harness Server config

# deprecated old REST_SERVER_HOST/PORT config used in Harness 0.4.x
# export HARNESS_URI="http://0.0.0.0:9090" # for external connections
export HARNESS_URI="${HARNESS_URI:-http://localhost:9090}"

# To configure Harness logging
export HARNESS_LOG_CONFIG="${HARNESS_HOME}/conf/logback.xml"
export HARNESS_LOG_PATH="${HARNESS_LOG_PATH:-$HARNESS_HOME/logs}"

# MongoDB setup
export MONGO_URI="${MONGO_URI:-mongodb://localhost:27017}"

# Elasticsearch setup (optional: used by UR and similar Engines)
# todo: need to allow for multiple servers for cluster operation of ES, which
#     is currently done in the sparkConf section of an Engine Instance config
export ELASTICSEARCH_URI="${ELASTICSEARCH_URI:-http://localhost:9200}"

# This setting helps mark spark train jobs as expired if they do not respond for this period of time
export JOBS_EXPIRE_AFTER="12 hours"

# Use only when necessary to pass options to the launcher for Harness
# for example below we set the heap size for the JVM, otherwise the JVM has a default, which is correct in many cases
# also in the example we use a more concurrent Garbage Collector, to avoid pauses in Harness execution for GC
# HARNESS_OPTS=" -J-Xmx4G -J-XX:+UseConcMarkSweepGC "


# ======== FOR SIMPLE USE CASES LOOK NO FURTHER ===============

# =============================================================
# Only change if default vertical scaling is not sufficient
# =============================================================

# The maximum number of concurrently accepted connections.
# Note, that this setting limits the number of the connections on a best-effort basis.
# It does *not* strictly guarantee that the number of established TCP connections will never
# exceed the limit (but it will be approximately correct) because connection termination happens
# asynchronously. It also does *not* guarantee that the number of concurrently active handler
# flow materializations will never exceed the limit for the reason that it is impossible to reliably
# detect when a materialization has ended.
# See akka.http.server.max-connections at https://doc.akka.io/docs/akka-http/current/configuration.html
export HARNESS_MAX_CONNECTIONS=${HARNESS_MAX_CONNECTIONS:-1024}

# The maximum number of requests that are accepted (and dispatched to
# the application) on one single connection before the first request
# has to be completed.
# Incoming requests that would cause the pipelining limit to be exceeded
# are not read from the connections socket so as to build up "back-pressure"
# to the client via TCP flow control.
# A setting of 1 disables HTTP pipelining, since only one request per
# connection can be "open" (i.e. being processed by the application) at any
# time. Set to higher values to enable HTTP pipelining.
# This value must be > 0 and <= 1024.
# See akka.http.server.pipelining-limit at https://doc.akka.io/docs/akka-http/current/configuration.html
export HARNESS_MAX_REQUESTS=${HARNESS_MAX_REQUESTS:-16}

# =============================================================
# Only change if you are using HDFS for file storage
# =============================================================

# HDFS setup
# export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-"/etc/hadoop"}
# Files can be addressed as hdfs://<some-name-node>:9000 by default but change the master and port below
# if needed
# export HDFS_MASTER="${HDFS_MASTER:-localhost}"
# export HDFS_MASTER_PORT="${HDFS_MASTER_PORT:-9000}"

# =============================================================
# Only change to enable TLS/SSL
# =============================================================

# export HARNESS_SSL_ENABLED=true # to enable TLS/SSL using the rest below for "localhost" keys passwords and certs
export HARNESS_SSL_ENABLED=${HARNESS_SSL_ENABLED:-false}

# Harness TLS/SSL server support. A file needs to be provided even if TLS is not used, one is supplied for "localhost"
export HARNESS_KEYSTORE_PASSWORD="${HARNESS_KEYSTORE_PASSWORD:-changeit}"
export HARNESS_KEYSTORE_PATH="${HARNESS_KEYSTORE_PATH:-$HARNESS_HOME/conf/harness.jks}"

# Java and Python client SDKs use the following for TLS/SSL, not used by the server
# the file provided works with localhost, create your own for some other IP address
export HARNESS_SERVER_CERT_PATH="${HARNESS_SERVER_CERT_PATH:-$HARNESS_HOME/conf/harness.pem}"

# The Python CLI must connect to the external address of the server to use TLS, supply it here
# export HARNESS_EXTERNAL_ADDRESS=0.0.0.0 # address to listen on, 0.0.0.0 is typical for external connections
export HARNESS_EXTERNAL_ADDRESS="${HARNESS_EXTERNAL_ADDRESS:-localhost}"


# =============================================================
# Only used for Authentication
# =============================================================

# Harness Auth-Server setup
# export HARNESS_AUTH_ENABLED=true
export HARNESS_AUTH_ENABLED=${HARNESS_AUTH_ENABLED:-false}
export HARNESS_AUTH_URL="${HARNESS_AUTH_URL:-http://localhost:9099}"
# When auth is enabled there must be an admin user-id set so create one before turning on Auth
# Both the Harness server and the Python CLI need this env var when using Auth
export ADMIN_USER_ID="${ADMIN_USER_ID:-some-user-id}"
# The Python CLI needs to pass the user-id and user-secret to the Python SDK so when using Auth supply a pointer to
# the user-secret here.
export ADMIN_USER_SECRET_LOCATION="${ADMIN_USER_SECRET_LOCATION:-$HOME/.ssh/${ADMIN_USER_ID}.secret}"

# =============================================================
# Only needed if you use the Spark Job Server with Apache Livy
# =============================================================

# Spark Job Server (Apache Livy) setup
export SPARK_JOB_SERVER_URL="${SPARK_JOB_SERVER_URL:-http://localhost:8998}"

# Harness engines setup. Engines can be stored in 'mongo' or 'etcd'
export HARNESS_ENGINES_BACKEND="${HARNESS_ENGINES_BACKEND:-mongo}"

# Comma separated list of etcd endpoints
export HARNESS_ETCD_ENDPOINTS="${HARNESS_ETCD_ENDPOINTS:-http://localhost:2379}"

export SPARK_MONGO_URI=${SPARK_MONGO_URI:-$MONGO_URI}

export HARNESS_JOB_CONTROLLER_ENABLED=${HARNESS_JOB_CONTROLLER_ENABLED:-false}
